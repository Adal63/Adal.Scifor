{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# Tokenization function: Split text into words\n",
        "def tokenize(text):\n",
        "    # Basic tokenization: split by whitespace and lowercase\n",
        "    return text.lower().split()\n",
        "\n",
        "# Example usage of tokenization\n",
        "email = \"Win a prize now\"\n",
        "tokens = tokenize(email)\n",
        "print(\"Tokens:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsJJOgm_BCvE",
        "outputId": "7dcff015-45f6-4f2d-a851-b9de0cc40879"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['win', 'a', 'prize', 'now']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example training data: List of tuples (email, label)\n",
        "training_data = [\n",
        "    (\"Win a prize now\", \"Spam\"),\n",
        "    (\"Meeting tomorrow\", \"Not Spam\"),\n",
        "    (\"Win money\", \"Spam\"),\n",
        "    (\"Update meeting\", \"Not Spam\"),\n",
        "    (\"Prize guaranteed\", \"Spam\"),\n",
        "    (\"Tomorrow's update\", \"Not Spam\")\n",
        "]\n",
        "\n",
        "# Display training data\n",
        "print(\"Training Data:\", training_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quMLi6MDBMPW",
        "outputId": "b54fb06d-a187-43f2-de28-01cdfd04f39c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: [('Win a prize now', 'Spam'), ('Meeting tomorrow', 'Not Spam'), ('Win money', 'Spam'), ('Update meeting', 'Not Spam'), ('Prize guaranteed', 'Spam'), (\"Tomorrow's update\", 'Not Spam')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Calculate word counts for each label\n",
        "def calculate_word_counts(training_data):\n",
        "    word_counts = {\n",
        "        \"Spam\": defaultdict(int),\n",
        "        \"Not Spam\": defaultdict(int)\n",
        "    }\n",
        "    email_counts = {\n",
        "        \"Spam\": 0,\n",
        "        \"Not Spam\": 0\n",
        "    }\n",
        "\n",
        "    for email, label in training_data:\n",
        "        email_counts[label] += 1\n",
        "        for word in tokenize(email):\n",
        "            word_counts[label][word] += 1\n",
        "\n",
        "    return word_counts, email_counts\n",
        "\n",
        "# Calculate word counts and email counts from training data\n",
        "word_counts, email_counts = calculate_word_counts(training_data)\n",
        "print(\"Word Counts:\", word_counts)\n",
        "print(\"Email Counts:\", email_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCuqbn_JY6Q1",
        "outputId": "97303fee-d2f8-4387-9d71-239fb08bc62a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Counts: {'Spam': defaultdict(<class 'int'>, {'win': 2, 'a': 1, 'prize': 2, 'now': 1, 'money': 1, 'guaranteed': 1}), 'Not Spam': defaultdict(<class 'int'>, {'meeting': 2, 'tomorrow': 1, 'update': 2, \"tomorrow's\": 1})}\n",
            "Email Counts: {'Spam': 3, 'Not Spam': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Calculate prior probabilities\n",
        "def calculate_prior_probabilities(email_counts):\n",
        "    total_emails = sum(email_counts.values())\n",
        "    return {label: count / total_emails for label, count in email_counts.items()}\n",
        "\n",
        "# Calculate priors\n",
        "priors = calculate_prior_probabilities(email_counts)\n",
        "print(\"Prior Probabilities:\", priors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVaEnk7dZKym",
        "outputId": "9103eec3-efa1-4a95-9a64-f1a6d731d7a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior Probabilities: {'Spam': 0.5, 'Not Spam': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vocabulary of all unique words\n",
        "vocab = set(word for email, _ in training_data for word in tokenize(email))\n",
        "print(\"Vocabulary:\", vocab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8T2b5F-ZdLu",
        "outputId": "289fdb1b-2ba9-497c-d6e2-b6a586d118dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: {'tomorrow', 'meeting', \"tomorrow's\", 'a', 'prize', 'now', 'guaranteed', 'win', 'update', 'money'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Calculate likelihoods with Laplace smoothing\n",
        "def calculate_likelihoods(word_counts, vocab):\n",
        "    likelihoods = {label: defaultdict(float) for label in word_counts}\n",
        "    vocab_size = len(vocab)\n",
        "\n",
        "    for label, counts in word_counts.items():\n",
        "        total_words = sum(counts.values())\n",
        "        for word in vocab:\n",
        "            # Laplace smoothing: (count + 1) / (total_words + vocab_size)\n",
        "            likelihoods[label][word] = (counts[word] + 1) / (total_words + vocab_size)\n",
        "\n",
        "    return likelihoods\n",
        "\n",
        "# Calculate likelihoods\n",
        "likelihoods = calculate_likelihoods(word_counts, vocab)\n",
        "print(\"Likelihoods:\", likelihoods)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdjlMMDMZinU",
        "outputId": "91be945c-bb8b-4f27-a649-24925591c2d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Likelihoods: {'Spam': defaultdict(<class 'float'>, {'tomorrow': 0.05555555555555555, 'meeting': 0.05555555555555555, \"tomorrow's\": 0.05555555555555555, 'a': 0.1111111111111111, 'prize': 0.16666666666666666, 'now': 0.1111111111111111, 'guaranteed': 0.1111111111111111, 'win': 0.16666666666666666, 'update': 0.05555555555555555, 'money': 0.1111111111111111}), 'Not Spam': defaultdict(<class 'float'>, {'tomorrow': 0.125, 'meeting': 0.1875, \"tomorrow's\": 0.125, 'a': 0.0625, 'prize': 0.0625, 'now': 0.0625, 'guaranteed': 0.0625, 'win': 0.0625, 'update': 0.1875, 'money': 0.0625})}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Predict function\n",
        "def predict(email, priors, likelihoods):\n",
        "    # Tokenize the email\n",
        "    tokens = tokenize(email)\n",
        "\n",
        "    # Initialize posterior probabilities with the log of prior probabilities\n",
        "    posteriors = {label: np.log(priors[label]) for label in priors}\n",
        "\n",
        "    # Update posterior probabilities with the log of likelihoods\n",
        "    for label in priors:\n",
        "        for token in tokens:\n",
        "            if token in likelihoods[label]:  # Only consider words in the vocabulary\n",
        "                posteriors[label] += np.log(likelihoods[label][token])\n",
        "\n",
        "    # Return the class with the highest posterior probability\n",
        "    return max(posteriors, key=posteriors.get)\n",
        "\n",
        "# Example usage\n",
        "email = \"win a prize now\"\n",
        "predicted_class = predict(email, priors, likelihoods)\n",
        "print(\"Predicted class:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgGitBIHZtkx",
        "outputId": "7465c408-8019-49ef-c568-7ed2e6307847"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Spam\n"
          ]
        }
      ]
    }
  ]
}